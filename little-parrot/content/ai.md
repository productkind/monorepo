# Concepts

## AI

### Definition

Artificial Intelligence refers to an ability of a machine to perform tasks that typically require
human intelligence. This includes learning, comprehension, reasoning, problem-solving, perception,
language understanding, and more.

### Aspects

 - Nowadays most AI systems are based on machine learning, particularly deep learning.


## model

### Aspects

 - Always has an input and output.
 - Both the input and output can be in various forms such as text, images, audio, etc.
 - Models are created by training on large datasets.
 -




 - context
 - prompt
 - token
 - ai
 - LLM (Large Language Model)
 -



1. What
   **Definition:** Define the concept clearly and concisely
   **By the Platform:** Yes
2. Why
   **Definition:** Explain the need and/or the pain and/or the innovation
   **By the Platform:** Yes
3. When
   **Definition:** Explain real use-cases for the concept
   **By the Platform:** Yes
4. Like
   **Definition:** Describe a common phenomenon as metaphor
   **By the Platform:** Yes
4. Show

    - The concept is explained by directly showing the happy case
5. Guide
    - Showing counter examples, common mistakes, and nested examples
6. Recognize
    - Able to spot the concept in context
7. Fix
    - Able to correct the concept
8. Try
    - Able to reproduce the concept based on example
9. Translate
    - Able to use the concept with explicit instructions
10. Express
    - Able to use the concept with implicit instructions
11. Pick
    - Able to use and pick the concept as correct sub-task/sub-concept with explicit instructions
12. Reason
    - Able to use and pick the concept as correct sub-task/sub-concept with implicit instructions




## Cards


### Video

In general, Artificial Intelligence refers to the ability of a machine to perform tasks that
typically require human intelligence. This includes learning, comprehension, reasoning,
problem-solving, perception, and language understanding.

Many problems are too complex to be solved by traditional programming techniques. AI provides a way
to tackle these problems and help automate tasks that would otherwise require human intervention.

Nowadays, in our day-to-day life, when we are using systems like ChatGPT or Gemini, we refer to
them as Artificial Intelligence, but they are Large Language Models that are just one type of AI.

Let's define what an LLM is. For that, we need to understand what an AI model is.

An AI Model is a program trained on a set of data to perform specific tasks such as recognizing
patterns, making decisions, predicting, or generating content.

A Model always has an input and output. Both the input and output can be in various forms such as
text, images, audio, etc.

An LLM is a type of AI model that is specifically designed to understand and generate human
language. It is trained on vast amounts of text data to learn the patterns and structures of
language.

### Quiz



### Video

LLMs are the form of AI that you encounter most often in your day-to-day life. It's likely that
you have used them in a chat setup, like ChatGPT, and maybe you had the impression that you are
talking with a thinking being. But in reality LLMs are not thinking, just predicting the output.
To understand how they work, we need to understand what a token is.

A token is a unit of text that the model processes. It can be a word, part of a word, or even
punctuation. When you give an input to an LLM, it breaks down the text into tokens,
then based on the input tokens it predicts the next token in the sequence. This process continues
until it generates a complete response.

The predictions are based on the patterns and relationships learned during training.

This means you can think of an LLM as a very advanced autocomplete system that predicts the next
word or phrase based on the context provided by the input tokens.

This also means that LLMs do not have a deep understanding of the content they generate.

When the output is not correct, or has mistakes we usually say that the model is hallucinating.

It is better to have the mental model that LLMs are always hallucinating, and in most of the
cases they are hallucinating outputs that are useful and correct.

Because of this prediction based nature, you can expect totally different output for asking
verifications on a previous output, or asking the same question multiple times.
